import pyspark.sql.functions as F

from {{project_name}}.jobs.common import Job
from typing import Dict, Any

class SampleJob(Job):
    def launch(self, **kwargs):
        self.logger.info("Launching the batch job")
        source = (
            self.spark
                .range(0, 1000).toDF("id")
                .withColumn("value", F.rand())
        )
        source.show(kwargs["num_rows"])
        self.logger.info("Batch job finished")

if __name__ == '__main__':
    job  = SampleJob()
    job.launch(num_rows=20)
