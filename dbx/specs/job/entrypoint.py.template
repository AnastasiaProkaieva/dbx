import pyspark.sql.functions as F

from {{project_name}}.jobs.common import Job
from typing import Dict, Any

class SampleJob(Job):
    def launch(self):
        self.logger.info("Launching the batch job")
        source = (
            self.spark
                .range(0, 1000).toDF("id")
                .withColumn("value", F.rand())
        )
        source.show(self.conf["num_rows"])
        self.logger.info("Batch job finished")

    @property
    def dev_config(self):
        return {"num_rows": 10}

if __name__ == '__main__':
    job = SampleJob()
    job.launch()
